<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Scrolling Nav - <a href="https://www.ai-camp.org">A.I. Camp</a></title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
            <div class="container px-4">
                <a class="navbar-brand" href="#page-top">A.I. Camp</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto">
                        <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link" href="#use">Use</a></li>
                        <li class="nav-item"><a class="nav-link" href="#charts">Charts</a></li>
                        <li class="nav-item"><a class="nav-link" href="#machine-learning">Machine Learning</a></li>
                        <li class="nav-item"><a class="nav-link" href="#conclusion">Conclusion</a></li>
                        <li class="nav-item"><a class="nav-link" href="#team">The Team</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Header-->
        <header class="masthead" style="background-image: url('https://image.cnbcfm.com/api/v1/image/104780481-IMG_6947-1.jpg?v=1508335390'); color: white;">
          <div class="container">
          <div class="container px-4 text-center">
            <h1 class="fw-bolder"><u>Predicting Airline Satisfaction</u></h1>
              <p class="lead">Finding out whether someone did or did not enjoy their flight with machine learning!</p>
            </div>
           </div>
        </header>
        <!-- About section-->
        <section class="bg-light" id="about">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>What is our website about?</h2>
                        <p class="lead">Our team created a website to show how we can predict whether a passenger was satisfied or not on an airplane with visualizations and models. </p>
                      </div>
                 </div>
              </div>
          </section>
         <!--Use section-->
         <section id="use">
           <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                                <h2>What did we use?</h2>
                        <p>For our project we used:</p>
                          <ul>
                          <li>Kaggle for our dataset: <a href="https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction">Our Dataset</a></li>
                          <li>Python as our coding language.</li>
                          <li>Pandas to make our dataset usable to code.</li>
                          <li>Plotly to make visualizations.</li>
                          <li>SKLearn for our machine learning.</li>
                          <li>HTML in order to make this website!</li>
                        </ul>
                      </div>
                  </div>
             </div>
              </section>
        <!-- Charts section-->
        <section class="bg-light" id="charts">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                      <h2>Charts</h2>
                      <iframe width="750" height="500" title="On-board Service" src="plots/obs_pie.html"></iframe>
                      <p>
                       The percentage of people who are satisfied or unsatisfied based on the on-board service. In the satisfied section, we can see very little people in the 1 and 2 rating category. In the unsatisfied section, the 5 ratings are pretty even.
                      </p>
                      <br>
                       <html>    
                        <body> 
                          <a href="pie_chart.html#top">
                          <button class="button1">Click Here For More Pie Charts</button>
                          </a>
                        </body>    
                      </html>
                      <p><br></p>
                      <iframe width="800" height="752" title="Correlation Matrix" src="plots/correlation_matrix_resized.html"></iframe> 
                      <p>
                        The amount each of our variables correlate. The closer to 0 the less the correlation, the closer to 1 the correlation increases positively, and the closer to -1 the correlation increases negatively. Most of our variables don't really correlate. The only column/row we care about is the satisfaction column/row. Most of them don't really correlate but Online Boarding and Business Class have a .5 correlation.
                      </p>
                    <html>    
                        <body>
                          <iframe width="750" height="500" title="Class Satisfaction" src="plots/class_satisfaction_hist.html"></iframe>
                      <p>
                      The amount of people who are either satisfied or neutral/dissatisfied, in relation to their class. Customers in business class are drastically more likely to be satisfied with their flight, while those in eco are drastically more likely to be dissatisfied/neutral. This is most likely because of the different reasons for travel, and the contrasting quality of flight.</p>
                       <br>
                        <a href="histogram.html#top">
                          <button class="button1">Click For More Histograms</button>
                          </a>
                        </body>    
                      </html>
                      <p><br></p>
                      <iframe width="750" height="500" title="Type/Flight Box Plot" src="plots/flight_distance_tt.html"></iframe> <!-- Doesn't make sense -->
                  <p>
                   Shows the amount of people who are satisfied based on whether they go business or personal. More people are satisfied when they go business.
                  </p>
                      <iframe width="750" height="500" title="Gender/Age Box Plot" src="plots/gender_age.html"></iframe>
                  <p>
                    This shows the age and gender of people who are satisfied and unsatisfied. Women and men have the same amount of satisfaction. On average, people aged 25-50 are the most commonly unsatisfied while people aged 32-51 on average are satisfied. Older people have more satisfaction in general.
                  </p>
                      <iframe width="750" height="500" title="Delay Convenience Scatter" src="plots/delay+convinience_scat.html"></iframe>
                  <p>
                    Shows the correlation between satisfied and unsatisfied customers in an arrival and departure delay. The longer a delay occurs, the more customers become dissatisfied.
                  </p>
                      
                      <iframe width="800" height="752" title="Scatter Matrix" src="plots/scatter_matrix_resized.html"></iframe> 
                      <p>
                        Takes various variables and plots each one. From the selected variables, the only ones that correlate are Departure Delay and Arrival Delay, but this doesn't give us any new information.
                      </p>
                      
                      <iframe width="750" height="500" title="Class/Age Satisfaction" src="plots/box_graph_age_class.html"></iframe>
                  </div>
                </div>
            </div>
        </section>
        <section id="machine-learning">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Machine Learning</h2>
                        <p class="lead">
                          In order to make accurate predictions, we tested a variety of machine learning models. They each functioned differently and used different methods to make predictions, generating a variety of outcomes. We used four metrics: precision, recall, accuracy, and f-1 score to compare the effectiveness of each model at making predictions, and we’ll refer to these collectively as PRAF. We also used a process called hyperparameter tuning (through a function called GridSearchCV) to improve each model’s “base performance”, sort of like getting the model familiar with how the data would be organized before it started processing.
                        </p>
                      <br>
                      <h3>Random Forest Model</h3>
                        <p class="descript-text">
                          A Random Forest model is a model that generates a given number of randomized decision trees and uses averaging functions to combine its results from the trees and make predictions on the data. This allows for more accurate predictions as randomizing decision trees allows the model to individually look for correlations between sections of the dataset, making predictions more intuitive, compared to looking at the entire dataset through one decision tree, as it is harder to find patterns when there are more variables to consider. <br> <br> Through hyperparameter tuning, we found that a larger number of trees correlated to a more accurate result, though by ~30 trees, the increase in accuracy was negligible compared to the amount of added processing time the model took. After hyperparameter tuning, the Random Forest model was quite effective in making predictions based on our data. It had a PRAF of ~0.95, meaning that it was making accurate predictions 95% of the time.
                        </p>
                        <figure>
                          <img src= "assets/random-forest-diagram.svg" alt="Random Forest Diagram" width = "600px" height = "350px"> 
                          <figcaption>Image courtesy of <a href="https://www.tibco.com/reference-center/what-is-a-random-forest">Tibco</a></figcaption>
                        </figure>
                      <br>
                        <h3>Categorical Naive Bayes Model</h3>
                        <p class="descript-text">
                          The Categorical Naive Bayes model works using the Bayes Theorem, an algorithm that assigns probabilities to individual features and uses those probabilities to predict an outcome. It assumes that individual features are dependent on each other, which works well with our dataset. We chose the Categorical Native Bayes model because it works best for categorical data and we have a lot of categorical data in the form of 1-5 ratings for the airline's performance. <br> <br> During hyperparameter tuning, we found that an alpha (a factor that smooths the data for outliers) value of 3 seemed to slightly improve the model, but further increases in alpha didn't make a significant difference. After hyperparameter tuning, the Categorical Naive Bayes model had a PRAF of ~0.9, meaning that it was making accurate predictions around 90% of the time.
                        </p>
                        <figure>
                          <img src="assets/bayes_theorem.png" alt="Naive Bayes Diagram"width = "600px" height = "350px">
                          <figcaption>Image courtesy of <a href="https://luminousmen.com/post/data-science-bayes-theorem">luminousmen</a></figcaption>
                        </figure>
                      <br>
                      <h3>Decision Tree Model</h3> 
                      <p class="descript-text">
                        A Decision Tree Classifier uses the given data to generate a decision tree, a group of “questions” that make up several paths to different outcomes. For each prediction, the decision tree uses the testing data to answer these “questions” and follows a path based on its answers. Upon reaching a set depth, or length of the path, the model then produces a prediction based on the path it followed. <br> <br> Through hyperparameter tuning, we found that a maximum depth of 4 and a minimum sample leaf (a value that requires a set amount of training data before the model can create a “question”) of 5 were the most effective hyperparameters for our data. After hyperparameter tuning, the Decision Tree Classifier model had a PRAF of 0.85, meaning that it was making accurate predictions around ~85% of the time.
                      </p>
                      <figure>
                        <img src= "assets/tree.jpg" alt="Decision Tree Diagram" width = "600px" height = "350px">
                        <figcaption>Image from model output</figcaption>
                      </figure>
                      <br>
                      <h3>K-Nearest Neighbors Model</h3> 
                      <p class="descript-text">
                        A K-Nearest Neighbors model is a classification model that works by finding the distance between a piece of testing data and all the training data in the dataset. A k-value is used to find the k-number of closest training data points. The model finds which class the majority of the k-closest data points are in, and classifies the testing data point to that class. <br> <br> Through hyperparameter tuning, we found that a k-value of 3 works best, and weighting the data (assigning different “priorities” to each data point based on a certain factor) based on their distance from the testing point was most effective. After hyperparameter tuning, the K-Nearest Neighbors model had a PRAF of ~0.63, meaning that it was not making a lot of accurate predictions around 63% of the time, which is not very good.
                      </p>
                      <figure>
                        <!-- Find an image!!! -->
                        <figcaption>Image</figcaption>
                      </figure>
                      <br>
                      <h3>AdaBoost Classifier Model</h3> 
                      <p class="descript-text">
                        The AdaBoost Classifier model makes a bunch of smaller, “weak learning” models that perform about as good as random guessing. After each weak learning model is made, it makes predictions on the testing data, and the predictions that the model gets wrong are given a heavier weight, meaning that the next weak learning model will focus on getting that prediction right. After creating a bunch of these weak learning models, the classifier combines all the results of the models to create a majority result that is used to make the final predictions. <br> <br> We didn’t perform hyperparameter testing on this model, so our results used the default hyperparameters. The AdaBoost Classifier model had a PRAF of ~0.9, which is actually pretty good for an untuned model, predicting accurately around 90% of the time.
                      </p>
                      <figure>
                        <img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_adaboost_hastie_10_2_001.png" alt="Naive Bayes Diagram"width = "600px" height = "350px">
                        <figcaption>Image courtesy of <a href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost">SKLearn</a></figcaption>
                      </figure>
                      <br>
                      <h3>Logistic Regression Model</h3> 
                      <p class="descript-text">
                        The AdaBoost Classifier model makes a bunch of smaller, “weak learning” models that perform about as good as random guessing. After each weak learning model is made, it makes predictions on the testing data, and the predictions that the model gets wrong are given a heavier weight, meaning that the next weak learning model will focus on getting that prediction right. After creating a bunch of these weak learning models, the classifier combines all the results of the models to create a majority result that is used to make the final predictions. <br> <br> We didn’t perform hyperparameter testing on this model, so our results used the default hyperparameters. The AdaBoost Classifier model had a PRAF of ~0.9, which is actually pretty good for an untuned model, predicting accurately around 90% of the time.
                      </p>
                      <figure>
                        <img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_adaboost_hastie_10_2_001.png" alt="Naive Bayes Diagram"width = "600px" height = "350px">
                        <figcaption>Image courtesy of <a href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost">SKLearn</a></figcaption>
                      </figure>
                      <br>
                      <h3>Stochastic Gradient Descent Model</h3> 
                      <p class="descript-text">
                        The AdaBoost Classifier model makes a bunch of smaller, “weak learning” models that perform about as good as random guessing. After each weak learning model is made, it makes predictions on the testing data, and the predictions that the model gets wrong are given a heavier weight, meaning that the next weak learning model will focus on getting that prediction right. After creating a bunch of these weak learning models, the classifier combines all the results of the models to create a majority result that is used to make the final predictions. <br> <br> We didn’t perform hyperparameter testing on this model, so our results used the default hyperparameters. The AdaBoost Classifier model had a PRAF of ~0.9, which is actually pretty good for an untuned model, predicting accurately around 90% of the time.
                      </p>
                      <figure>
                        <img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_adaboost_hastie_10_2_001.png" alt="Naive Bayes Diagram"width = "600px" height = "350px">
                        <figcaption>Image courtesy of <a href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost">SKLearn</a></figcaption>
                      </figure>
                    </div>
                </div>
             </div>
        </section>
        <!-- Conclusion section-->
                            <iframe width="750" height="500" title="Type/Flight Box Plot" src="plots/.html"></iframe>
        <section class = "bg-light" id="conclusion">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Conclusions</h2>
                        <h2>So What?</h2>
                    </div>
                </div>
            </div>
        </section>
        <!-- Team section-->
        <section id="team">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                      <h2>Frenzied Physicists</h2>
                      <p class="lead">Meet the team who built these visualizations and models!</p>
                      <h4>Andrea</h4>
                      <p class="descript-text">Hi! My name is Andrea Mireles, and I’m a junior at MSMS. This is my first time coding and creating a website. I was the co-designer of this website and made a few graphs like the box and whisker plot for gender and age satisfaction. I’ve learned so much at A.I. Camp and am very happy that I spent the summer learning more about programming and A.I.</p>
                      <h4>Angela</h4>
                      <p class="descript-text">I'm Angela, I'm a junior in high school in Cypress, Texas and this is my first time coding. I learned a lot from this experience in a very short time span, and met a lot of interesting people. I built parts of the histograms and box plots, and also wrote the descriptions for all of the visualizations with help from the rest of the team. </p>
                      <h4>Ishani</h4>
                      <p class="descript-text">description</p>
                      <h4>Isaac</h4>
                      <p class="descript-text">My name is Isaac Mallory, I am 17 and from Cincinnati, Ohio. I have always had an interest in programming but didn't actually start until a year ago and this program has helped me increase my skills a lot. I developed some of the visualizations , wrote descriptions for them, and made the pie chart part of the website.</p>
                      <h4>Ivan</h4>
                      <p class="descript-text">Hello, my name is Ivan, I'm 15 and from Maryland. These past three weeks at AI Camp have been really enjoyable, and I'm glad I got to learn more about AI and data science! I made some of the graphs and machine learning models that we used, as well as all the explanations for those models on this website.</p>
                      <h4>Sebastian</h4>
                      <p class="descript-text">I'm Sebastian. I have always been interested in computers. I decided to take AI Camp so I can start going into a more specific field and start training in it. While I was here a learn a lot and improved my coding skills and knowledge. I made a few of the visualizations and I build and tuned the Decision Tree.
                      <p>
                        <h4>Anthony</h4>
                      <p class="descript-text">Leader of the team</p>
                    </div>
                </div>
            </div>
        </section>
        <footer class="py-5 bg-dark">
            <div class="container px-4"></div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
