{"backend_state":"running","connection_file":"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/share/jupyter/runtime/kernel-44151443-0743-4612-83d4-d0baf69cf5b2.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1657820149245,"exec_count":3,"id":"0f0e7c","input":"import pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport sklearn\nfrom sklearn import tree\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nimport pickle\nimport json\n\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier as ADC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import BallTree\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import GridSearchCV as GSearch\n\nfrom imblearn.under_sampling import RandomUnderSampler ","kernel":"ds_env","pos":0,"start":1657820149233,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820153973,"exec_count":4,"id":"8d0a90","input":"airline_df = pd.read_csv('./data/airline_data.csv')\nairline_df.dropna(inplace=True)\nairline_df.reset_index(drop=True, inplace=True)\nairline_df = pd.get_dummies(airline_df, prefix = None, prefix_sep = '_', dummy_na = False, columns = ['satisfaction','Gender', 'Customer Type', 'Type of Travel', 'Class'], sparse = False, drop_first = False, dtype = None)\ncolumns_drop = ['id', 'Unnamed: 0.1', 'Unnamed: 0', 'satisfaction_neutral or dissatisfied']\nairline_df.drop(columns_drop, axis=1, inplace = True)\n","kernel":"ds_env","pos":1,"start":1657820153213,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820162432,"exec_count":5,"id":"7fe2d6","input":"\nairline_df.dropna(inplace=True)\nairline_df.reset_index(drop=True, inplace=True)","kernel":"ds_env","pos":5,"start":1657820162405,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820163188,"exec_count":6,"id":"367556","input":"reduced_df = airline_df.sample(frac=0.10, random_state=42)\nreduced_df.shape","kernel":"ds_env","output":{"0":{"data":{"text/plain":"(12949, 28)"},"exec_count":6}},"pos":6,"start":1657820163159,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820171038,"exec_count":7,"id":"e4cc91","input":"reduced_df.satisfaction_satisfied.value_counts()","kernel":"ds_env","output":{"0":{"data":{"text/plain":"0    7323\n1    5626\nName: satisfaction_satisfied, dtype: int64"},"exec_count":7}},"pos":7,"start":1657820171015,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820171689,"exec_count":8,"id":"feaaac","input":"target = reduced_df['satisfaction_satisfied']","kernel":"ds_env","pos":8,"start":1657820171682,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820172335,"exec_count":9,"id":"79a877","input":"input_columns = reduced_df.loc[:, airline_df.columns != \"satisfaction_satisfied\"]","kernel":"ds_env","pos":9,"start":1657820172315,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820173460,"exec_count":10,"id":"3fd5e0","input":"input_columns.shape","kernel":"ds_env","output":{"0":{"data":{"text/plain":"(12949, 27)"},"exec_count":10}},"pos":10,"start":1657820173456,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820174020,"exec_count":11,"id":"a73399","input":"x_train, x_test, y_train, y_test = train_test_split(input_columns, target, stratify=target, train_size=0.8)","kernel":"ds_env","pos":11,"start":1657820174005,"state":"done","type":"cell"}
{"cell_type":"code","end":1657820182616,"exec_count":12,"id":"fda951","input":"RF_model = RandomForestClassifier(n_estimators=30, criterion=\"entropy\")\n\nRF_model.fit(x_train, y_train)\n\nRF_hat = RF_model.predict(x_test)\n\npickle.dump(RF_model, open('randomforest.pkl','wb'))\n\nrecall = sklearn.metrics.recall_score(y_test, RF_hat)\nprecision = sklearn.metrics.precision_score(y_test, RF_hat)\naccuracy = sklearn.metrics.accuracy_score(y_test, RF_hat)\nf_measure = sklearn.metrics.f1_score(y_test, RF_hat)\nprint(\"R: \", recall)\nprint(\"P: \", precision)\nprint(\"A: \", accuracy)\nprint(\"F: \", f_measure)\n\nsns.heatmap(confusion_matrix(y_test, RF_hat), annot=True, fmt='g')\n","kernel":"ds_env","output":{"0":{"name":"stdout","text":"R:  0.9048888888888889\nP:  0.9594721960414703\nA:  0.9420849420849421\nF:  0.9313815187557182\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":12},"2":{"data":{"image/png":"426f41281dfd16a06593a59edb15f4ba3885bdaf","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"}}},"pos":16,"scrolled":true,"start":1657820181577,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"56f8be","input":"","pos":39,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9bb551","input":"","pos":42,"type":"cell"}
{"cell_type":"code","exec_count":113,"id":"f07a91","input":"tree_gsearch.best_params_","output":{"0":{"data":{"text/plain":"{'max_leaf_nodes': 4,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0}"},"exec_count":113,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"b83f98","input":"tree_clf.fit(x_train, y_train)","output":{"0":{"data":{"text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>","text/plain":"DecisionTreeClassifier()"},"exec_count":17,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"04843c","input":"NB_model = CategoricalNB(alpha = 3)\n\nNB_model.fit(x_train, y_train)\n\nNB_hat = NB_model.predict(x_test)\n\nrecall = sklearn.metrics.recall_score(y_test,NB_hat)\nprecision = sklearn.metrics.precision_score(y_test, NB_hat)\naccuracy = sklearn.metrics.accuracy_score(y_test, NB_hat)\nf_measure = sklearn.metrics.f1_score(y_test, NB_hat)\nprint(\"R: \", recall)\nprint(\"P: \", precision)\nprint(\"A: \", accuracy)\nprint(\"F: \", f_measure)\n\nsns.heatmap(confusion_matrix(y_test, NB_hat), annot=True, fmt='g')\n\n# Ivan","output":{"0":{"name":"stdout","output_type":"stream","text":"R:  0.8782222222222222\nP:  0.903107861060329\nA:  0.9061776061776062\nF:  0.8904912122577738\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":18,"output_type":"execute_result"},"2":{"data":{"image/png":"76541e0d303484f9687513d098e60e5ed8c3b6e3","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":18,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"16de42","input":"tree_clf = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=4, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0)\ntree_clf = tree_clf.fit(x_train, y_train)\ny_pred_tree = tree_clf.predict(x_test)\nparams = {'min_samples_split': [1,2,3,4], 'min_samples_leaf': [1,2,3,4], 'min_weight_fraction_leaf': [-1.0,0.0,1.0], 'max_leaf_nodes': list(range(1,5))}\ntree_gsearch = GSearch(DecisionTreeClassifier(max_depth=7), params)\ntree_gsearch.fit(x_train, y_train)\nfig = plt.figure(figsize=(25,20))\n_ = tree.plot_tree(tree_clf,\n                   feature_names=input_columns.columns,  \n                   class_names=['Not Satisfied','Satisfied'],\n                   filled=True, fontsize=10)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\nprint(\"Precision:\", precision_score(y_test, y_pred_tree))\nprint(\"Recall:\", recall_score(y_test, y_pred_tree))\nprint(\"F1 Score:\", f1_score(y_test, y_pred_tree))","output":{"0":{"name":"stderr","output_type":"stream","text":"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n780 fits failed out of a total of 960.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 265, in fit\n    check_scalar(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n    raise ValueError(\nValueError: min_samples_split == 1, must be >= 2.\n\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 286, in fit\n    check_scalar(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n    raise ValueError(\nValueError: min_weight_fraction_leaf == -1.0, must be >= 0.0.\n\n--------------------------------------------------------------------------------\n60 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n    check_scalar(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n    raise ValueError(\nValueError: max_leaf_nodes == 1, must be >= 2.\n\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 286, in fit\n    check_scalar(\n  File \"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1489, in check_scalar\n    raise ValueError(\nValueError: min_weight_fraction_leaf == 1.0, must be <= 0.5.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan        nan        nan\n        nan        nan        nan        nan 0.78414905        nan\n        nan 0.78414905        nan        nan 0.78414905        nan\n        nan        nan        nan        nan 0.78414905        nan\n        nan 0.78414905        nan        nan 0.78414905        nan\n        nan        nan        nan        nan 0.78414905        nan\n        nan 0.78414905        nan        nan 0.78414905        nan\n        nan        nan        nan        nan 0.78414905        nan\n        nan 0.78414905        nan        nan 0.78414905        nan\n        nan        nan        nan        nan 0.84313185        nan\n        nan 0.84313185        nan        nan 0.84313185        nan\n        nan        nan        nan        nan 0.84313185        nan\n        nan 0.84313185        nan        nan 0.84313185        nan\n        nan        nan        nan        nan 0.84313185        nan\n        nan 0.84313185        nan        nan 0.84313185        nan\n        nan        nan        nan        nan 0.84313185        nan\n        nan 0.84313185        nan        nan 0.84313185        nan\n        nan        nan        nan        nan 0.85819107        nan\n        nan 0.85819107        nan        nan 0.85819107        nan\n        nan        nan        nan        nan 0.85819107        nan\n        nan 0.85819107        nan        nan 0.85819107        nan\n        nan        nan        nan        nan 0.85819107        nan\n        nan 0.85819107        nan        nan 0.85819107        nan\n        nan        nan        nan        nan 0.85819107        nan\n        nan 0.85819107        nan        nan 0.85819107        nan]\n  warnings.warn(\n"},"1":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.8656370656370657\nPrecision: 0.8363636363636363\nRecall: 0.8586666666666667\nF1 Score: 0.8473684210526315\n"},"2":{"data":{"image/png":"c43db889b8e2905785d8e0c1bda3d029d46605fd","text/plain":"<Figure size 1800x1440 with 1 Axes>"},"exec_count":19,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":18,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"50400c","input":"tree_clf = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=4, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0)\ntree_clf = tree_clf.fit(x_train, y_train)\ny_pred_tree = tree_clf.predict(x_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\nprint(\"Precision:\", precision_score(y_test, y_pred_tree))\nprint(\"Recall:\", recall_score(y_test, y_pred_tree))\nprint(\"F1 Score:\", f1_score(y_test, y_pred_tree))","output":{"0":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.8656370656370657\nPrecision: 0.8363636363636363\nRecall: 0.8586666666666667\nF1 Score: 0.8473684210526315\n"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"9a6ca1","input":"total_squared_error = (np.sum((y_test - adc_pred)**2))\nmean_squared_error = total_squared_error/len(y_test)\nprint(mean_squared_error)","output":{"0":{"name":"stdout","output_type":"stream","text":"0.07375086879295699\n"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"58798f","input":"SGD_model = SGDClassifier()\n\nparam_grid = {'loss': [\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],  \n              'penalty': [\"l2\", \"l1\", \"elasticnet\"], \n              'max_iter':[1000, 10000, 30000],\n              'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]}  \n   \ngrid = GridSearchCV(SGD_model, param_grid, refit = True, verbose = 3,n_jobs=-1) \n   \ngrid.fit(x_train, y_train) \n \nprint(grid.best_params_) \n\n# Ivan ","output":{"0":{"name":"stdout","output_type":"stream","text":"Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n"},"1":{"name":"stdout","output_type":"stream","text":"[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2;, score=0.787 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2;, score=0.602 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2;, score=0.495 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1;, score=0.771 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1;, score=0.802 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.502 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.826 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2;, score=0.554 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2;, score=0.535 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2;, score=0.737 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1;, score=0.779 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1;, score=0.784 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1;, score=0.791 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.503 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.631 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.641 total time=   0.6s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l2;, score=0.583 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l2;, score=0.573 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l1;, score=0.778 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l1;, score=0.785 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l1;, score=0.676 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.648 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.699 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.507 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.618 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.580 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.815 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.755 total time=   0.5s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.803 total time=   0.5s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.806 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.767 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.482 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.697 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.778 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.486 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.711 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.812 total time=   0.7s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.727 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.711 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.573 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.497 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.665 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.818 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.718 total time=   0.7s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.799 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.817 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.484 total time=   0.8s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.464 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.577 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.800 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.641 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.738 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.600 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.806 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.810 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.648 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.744 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.814 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.754 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.686 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.593 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.590 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.564 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.575 total time=   0.1s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.501 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.649 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.765 total time=   0.5s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.707 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.570 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.495 total time=   0.5s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.806 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.618 total time=   0.1s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.786 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.725 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.748 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.569 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.573 total time=   0.5s\n"},"10":{"name":"stdout","output_type":"stream","text":"[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.445 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.529 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.549 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.582 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.496 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.782 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.768 total time=   0.3s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.487 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.725 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.794 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.594 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.577 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.577 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.747 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.753 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.677 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.453 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.777 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.533 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.492 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.831 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.790 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.712 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.729 total time=   0.3s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.724 total time=   0.4s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.576 total time=   0.8s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.706 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.613 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.826 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.777 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.725 total time=   0.4s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.710 total time=   0.4s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.673 total time=   0.5s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.478 total time=   0.4s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.626 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.577 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.715 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.731 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.758 total time=   0.3s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.571 total time=   0.6s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.761 total time=   0.5s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.586 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2;, score=0.715 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2;, score=0.697 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1;, score=0.698 total time=   0.4s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1;, score=0.603 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.737 total time=   0.3s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.800 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l2;, score=0.604 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l2;, score=0.667 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l1;, score=0.717 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l1;, score=0.528 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.733 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.527 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.554 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l2;, score=0.591 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l2;, score=0.790 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l1;, score=0.666 total time=   0.3s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l1;, score=0.714 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.614 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.457 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.850 total time=   0.2s\n[CV 2/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l2;, score=0.597 total time=   0.1s\n[CV 3/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l2;, score=0.567 total time=   0.2s\n[CV 5/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l2;, score=0.668 total time=   0.1s\n[CV 1/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l1;, score=0.554 total time=   0.4s\n[CV 4/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l1;, score=0.476 total time=   0.3s\n[CV 1/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.578 total time=   0.3s\n[CV 3/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.566 total time=   0.3s\n[CV 5/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.579 total time=   0.4s\n[CV 3/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l2;, score=0.556 total time=   0.2s\n[CV 5/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l2;, score=0.673 total time=   0.2s\n[CV 2/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l1;, score=0.566 total time=   0.2s\n[CV 3/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l1;, score=0.500 total time=   0.3s\n[CV 4/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l1;, score=0.583 total time=   0.3s\n[CV 5/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l1;, score=0.555 total time=   0.8s\n[CV 1/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.654 total time=   0.2s\n[CV 2/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.559 total time=   0.3s\n"},"11":{"name":"stdout","output_type":"stream","text":"[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.821 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.634 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.747 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.805 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.747 total time=   0.6s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.642 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.698 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.579 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.504 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.764 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.729 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.809 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.844 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.612 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.833 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.531 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.765 total time=   0.4s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.751 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.833 total time=   0.4s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.832 total time=   0.5s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.771 total time=   0.4s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.712 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.783 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.769 total time=   0.4s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.778 total time=   0.3s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.586 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.835 total time=   0.4s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.704 total time=   0.4s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.623 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.842 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.690 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.740 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.748 total time=   0.6s\n[CV 2/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.718 total time=   0.4s\n[CV 4/5] END alpha=0.1, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.600 total time=   0.3s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2;, score=0.572 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2;, score=0.798 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2;, score=0.483 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1;, score=0.799 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1;, score=0.698 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1;, score=0.732 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.757 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.520 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.720 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l2;, score=0.487 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l2;, score=0.818 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l2;, score=0.788 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l1;, score=0.711 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l1;, score=0.736 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=l1;, score=0.749 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.842 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.602 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l2;, score=0.814 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l2;, score=0.493 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l2;, score=0.786 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l1;, score=0.675 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l1;, score=0.710 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=l1;, score=0.577 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.653 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.655 total time=   0.2s\n[CV 1/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l2;, score=0.661 total time=   0.3s\n[CV 4/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l2;, score=0.615 total time=   0.3s\n[CV 2/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l1;, score=0.606 total time=   0.3s\n[CV 3/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l1;, score=0.566 total time=   0.3s\n[CV 5/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=l1;, score=0.497 total time=   0.2s\n[CV 2/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.546 total time=   0.3s\n[CV 4/5] END alpha=1.0, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.581 total time=   0.2s\n[CV 1/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l2;, score=0.568 total time=   0.2s\n[CV 2/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l2;, score=0.644 total time=   0.2s\n[CV 4/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l2;, score=0.565 total time=   0.2s\n[CV 1/5] END alpha=1.0, loss=hinge, max_iter=10000, penalty=l1;, score=0.541 total time=  24.9s\n[CV 2/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.710 total time=   0.1s\n[CV 4/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.538 total time=   0.2s\n[CV 1/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.583 total time=   0.5s\n[CV 3/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.552 total time=   0.2s\n[CV 4/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.685 total time=   0.2s\n[CV 5/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.565 total time=   0.1s\n[CV 1/5] END alpha=1.0, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.562 total time=   0.4s\n"},"12":{"name":"stderr","output_type":"stream","text":"WARNING: Some output was deleted.\n"},"2":{"name":"stdout","output_type":"stream","text":"[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2;, score=0.809 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2;, score=0.571 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1;, score=0.800 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1;, score=0.782 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1;, score=0.778 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.712 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.573 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.775 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2;, score=0.546 total time=   0.1s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2;, score=0.782 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1;, score=0.789 total time=   0.5s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1;, score=0.804 total time=   0.5s\n[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.779 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.648 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l2;, score=0.609 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l2;, score=0.787 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l2;, score=0.809 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l1;, score=0.816 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=l1;, score=0.804 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.726 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.590 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.625 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.594 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.711 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.788 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.764 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.591 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.782 total time=   0.6s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.814 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.748 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.801 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.766 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.673 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.808 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.788 total time=   0.6s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.507 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.570 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.741 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.783 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.806 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.824 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.816 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.823 total time=   0.5s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.520 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.502 total time=   0.1s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.792 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.725 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.774 total time=   0.6s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.573 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.601 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.580 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.615 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.687 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.682 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.783 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.648 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.570 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.726 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.801 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.668 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.776 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.758 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.591 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.746 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.565 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.569 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.572 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.602 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.726 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.662 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.778 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.476 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.711 total time=   0.3s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.781 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.578 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.725 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.679 total time=   0.4s\n"},"3":{"name":"stdout","output_type":"stream","text":"[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.801 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.572 total time=   0.1s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.655 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.723 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.707 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.790 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.763 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.707 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.813 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.642 total time=   0.1s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.669 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.714 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.760 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.553 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.754 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.572 total time=   0.1s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.708 total time=   0.1s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.540 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.761 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.786 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.809 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.837 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.753 total time=   0.5s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.583 total time=   0.3s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.532 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.628 total time=   0.1s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.525 total time=   0.1s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.758 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.818 total time=   0.6s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.789 total time=   0.6s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.624 total time=   0.4s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.533 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.566 total time=   0.2s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.761 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.782 total time=   0.3s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.798 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.616 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.640 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.810 total time=   0.6s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l2;, score=0.619 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l1;, score=0.815 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l1;, score=0.804 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.859 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.861 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.855 total time=   0.5s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l2;, score=0.605 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l2;, score=0.514 total time=   0.1s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l1;, score=0.788 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l1;, score=0.817 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.797 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.456 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.863 total time=   0.4s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l2;, score=0.673 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l2;, score=0.572 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l1;, score=0.787 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l1;, score=0.794 total time=   0.1s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l1;, score=0.797 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.860 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.868 total time=   0.4s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.735 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.570 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.605 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.783 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.805 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.859 total time=   0.6s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.447 total time=   0.5s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.860 total time=   0.6s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.496 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.800 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.790 total time=   0.5s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.802 total time=   0.4s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.856 total time=   0.7s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.869 total time=   0.9s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.817 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.475 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.590 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.787 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.799 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.760 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.813 total time=   0.6s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.547 total time=   0.2s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.482 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.597 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.728 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.726 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.769 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.706 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.729 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.680 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.602 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.750 total time=   0.6s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.787 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.802 total time=   0.5s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.777 total time=   0.5s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.500 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.605 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.584 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.809 total time=   0.2s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.790 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.800 total time=   0.5s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.603 total time=   0.5s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.792 total time=   0.4s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.582 total time=   0.4s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.776 total time=   0.2s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.476 total time=   0.2s\n[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.810 total time=   0.4s\n[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.787 total time=   0.3s\n[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.802 total time=   0.3s\n[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.601 total time=   0.4s\n[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.829 total time=   0.4s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l2;, score=0.691 total time=   0.1s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l2;, score=0.787 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l2;, score=0.568 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l2;, score=0.539 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l1;, score=0.784 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l1;, score=0.784 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=l1;, score=0.805 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.747 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.861 total time=   0.5s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l2;, score=0.801 total time=   0.1s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l2;, score=0.760 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l2;, score=0.567 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l1;, score=0.810 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l1;, score=0.786 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=l1;, score=0.797 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.855 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.861 total time=   0.4s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l2;, score=0.603 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l2;, score=0.543 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l2;, score=0.574 total time=   0.1s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l1;, score=0.807 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=l1;, score=0.793 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.860 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.778 total time=   0.5s\n[CV 5/5] END alpha=0.001, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.854 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.795 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l2;, score=0.702 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.658 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.770 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=l1;, score=0.802 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.811 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.864 total time=   0.6s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.816 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.513 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l2;, score=0.812 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.812 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.783 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=l1;, score=0.806 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.859 total time=   0.8s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.862 total time=   0.6s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.840 total time=   0.5s\n[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.462 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l2;, score=0.720 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.803 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.780 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=l1;, score=0.801 total time=   0.4s\n"},"4":{"name":"stdout","output_type":"stream","text":"[CV 2/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.846 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.855 total time=   0.6s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.579 total time=   0.1s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.753 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.772 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.778 total time=   0.5s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.797 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.843 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.794 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.848 total time=   0.5s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.465 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.810 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.814 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.780 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.795 total time=   0.4s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.808 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.514 total time=   0.5s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.845 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.721 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.735 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.778 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.817 total time=   0.4s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.849 total time=   0.5s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.863 total time=   0.6s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.559 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.571 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.827 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.825 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.762 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.758 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.805 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.601 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.572 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.500 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.766 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.626 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.657 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.741 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.764 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.608 total time=   0.5s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.573 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.831 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.573 total time=   0.1s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.718 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.786 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.789 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.799 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.694 total time=   0.6s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.469 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.589 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.807 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.806 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.742 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.856 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.719 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.526 total time=   0.1s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.479 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.576 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.805 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.774 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.799 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.804 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.861 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.851 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.479 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.803 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.780 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.768 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.852 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.856 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2;, score=0.593 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2;, score=0.611 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2;, score=0.499 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1;, score=0.778 total time=   0.1s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1;, score=0.792 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1;, score=0.800 total time=   0.1s\n"},"5":{"name":"stdout","output_type":"stream","text":"[CV 1/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.857 total time=   0.5s\n[CV 3/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.463 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.847 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.774 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.582 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.807 total time=   0.5s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.788 total time=   0.5s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.789 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.785 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.576 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.818 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.723 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.641 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.748 total time=   0.3s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.794 total time=   0.4s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.832 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.720 total time=   0.5s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.769 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.615 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.753 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.809 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.778 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.795 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.800 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.861 total time=   0.5s\n[CV 5/5] END alpha=0.001, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.849 total time=   0.5s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.557 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.797 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.727 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.779 total time=   0.4s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.619 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.484 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.744 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.659 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.829 total time=   0.3s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.787 total time=   0.5s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.757 total time=   0.4s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.551 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.579 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.496 total time=   0.4s\n[CV 2/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.479 total time=   0.1s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.486 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.798 total time=   0.3s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.744 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.643 total time=   0.4s\n[CV 3/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.595 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.500 total time=   0.5s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.812 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.737 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l2;, score=0.592 total time=   0.1s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.789 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.790 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=l1;, score=0.805 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.865 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.857 total time=   0.4s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.574 total time=   0.2s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l2;, score=0.568 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.709 total time=   0.4s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=l1;, score=0.794 total time=   0.2s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.858 total time=   0.4s\n[CV 4/5] END alpha=0.001, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.858 total time=   0.3s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.767 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.613 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.791 total time=   0.2s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l2;, score=0.560 total time=   0.2s\n[CV 2/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.794 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=l1;, score=0.781 total time=   0.1s\n[CV 1/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.822 total time=   0.2s\n[CV 3/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.861 total time=   0.3s\n[CV 5/5] END alpha=0.001, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.850 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2;, score=0.797 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2;, score=0.628 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1;, score=0.806 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1;, score=0.772 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.704 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.833 total time=   0.2s\n"},"6":{"name":"stdout","output_type":"stream","text":"[CV 5/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.851 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2;, score=0.628 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2;, score=0.641 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2;, score=0.519 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1;, score=0.769 total time=   0.1s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1;, score=0.798 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.641 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.614 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.737 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l2;, score=0.624 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l2;, score=0.595 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l1;, score=0.786 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l1;, score=0.787 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l1;, score=0.794 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.687 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.694 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2;, score=0.681 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2;, score=0.695 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2;, score=0.589 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1;, score=0.766 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1;, score=0.788 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1;, score=0.794 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.850 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.762 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.735 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2;, score=0.823 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2;, score=0.737 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1;, score=0.807 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1;, score=0.786 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1;, score=0.778 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1;, score=0.787 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.839 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.782 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l2;, score=0.799 total time=   0.4s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l2;, score=0.847 total time=   0.5s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l1;, score=0.764 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l1;, score=0.778 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l1;, score=0.791 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.725 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.859 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.705 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.799 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.577 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.784 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.776 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.833 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.861 total time=   0.4s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.580 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.661 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.491 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.805 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.786 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.582 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.824 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.857 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.707 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.638 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.796 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.771 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.805 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.848 total time=   0.5s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.792 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.697 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.624 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.798 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.770 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.729 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.578 total time=   0.4s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.819 total time=   0.4s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.590 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.593 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.807 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.482 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.672 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.681 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.675 total time=   0.7s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.741 total time=   0.5s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.618 total time=   0.7s\n"},"7":{"name":"stdout","output_type":"stream","text":"[CV 2/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.462 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.446 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2;, score=0.519 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2;, score=0.611 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1;, score=0.804 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1;, score=0.775 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1;, score=0.764 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.644 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.847 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l2;, score=0.596 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l2;, score=0.635 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l2;, score=0.575 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l1;, score=0.773 total time=   0.1s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=l1;, score=0.795 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.645 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.727 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.542 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2;, score=0.569 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2;, score=0.734 total time=   0.4s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1;, score=0.820 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1;, score=0.777 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.757 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.856 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2;, score=0.835 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2;, score=0.799 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2;, score=0.786 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1;, score=0.786 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.750 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.841 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.841 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l2;, score=0.590 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l2;, score=0.617 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l2;, score=0.750 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l1;, score=0.806 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=l1;, score=0.806 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.706 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.848 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.852 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.795 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.478 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.811 total time=   0.5s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.797 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.800 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.769 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.782 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.850 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.834 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l2;, score=0.545 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.791 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.795 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=l1;, score=0.807 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.840 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=10000, penalty=elasticnet;, score=0.498 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.614 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.813 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l2;, score=0.735 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.792 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=l1;, score=0.752 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.859 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.828 total time=   0.4s\n[CV 4/5] END alpha=0.01, loss=modified_huber, max_iter=30000, penalty=elasticnet;, score=0.620 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.525 total time=   0.1s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.568 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.635 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.768 total time=   0.4s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.783 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.781 total time=   0.5s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.569 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.807 total time=   0.5s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2;, score=0.462 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.770 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.776 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1;, score=0.739 total time=   0.6s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.503 total time=   0.4s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet;, score=0.810 total time=   0.7s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.619 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.813 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.721 total time=   0.2s\n"},"8":{"name":"stdout","output_type":"stream","text":"[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.472 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l2;, score=0.577 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.755 total time=   0.4s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.755 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.558 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.527 total time=   0.4s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.573 total time=   0.6s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2;, score=0.480 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2;, score=0.588 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1;, score=0.746 total time=   0.1s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1;, score=0.792 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.808 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.517 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.779 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2;, score=0.661 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2;, score=0.608 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1;, score=0.800 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1;, score=0.771 total time=   0.3s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1;, score=0.797 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1;, score=0.796 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.744 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.856 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l2;, score=0.593 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l2;, score=0.571 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l2;, score=0.568 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l1;, score=0.762 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l1;, score=0.796 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.680 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.702 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.770 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2;, score=0.645 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2;, score=0.654 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1;, score=0.720 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1;, score=0.525 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1;, score=0.706 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.701 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.705 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l2;, score=0.614 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l2;, score=0.817 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l2;, score=0.577 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l1;, score=0.673 total time=   0.1s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l1;, score=0.600 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l1;, score=0.683 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.469 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.449 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l2;, score=0.651 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l2;, score=0.567 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l1;, score=0.574 total time=   0.6s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l1;, score=0.586 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.688 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.738 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.833 total time=   0.4s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l2;, score=0.500 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l2;, score=0.745 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l1;, score=0.756 total time=   0.4s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l1;, score=0.743 total time=   0.5s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.695 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.791 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.591 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l2;, score=0.583 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l2;, score=0.595 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l2;, score=0.665 total time=   0.5s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l1;, score=0.537 total time=   0.5s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l1;, score=0.761 total time=   0.5s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.794 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.753 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l2;, score=0.530 total time=   0.3s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l2;, score=0.601 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l1;, score=0.688 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l1;, score=0.536 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l1;, score=0.446 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l1;, score=0.748 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.452 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.816 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.620 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.565 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.586 total time=   0.4s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.757 total time=   0.3s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.794 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.699 total time=   0.1s\n"},"9":{"name":"stdout","output_type":"stream","text":"[CV 1/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.745 total time=   0.4s\n[CV 3/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.770 total time=   0.3s\n[CV 5/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=l1;, score=0.707 total time=   0.3s\n[CV 2/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.741 total time=   0.4s\n[CV 4/5] END alpha=0.01, loss=squared_hinge, max_iter=30000, penalty=elasticnet;, score=0.516 total time=   0.3s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2;, score=0.529 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2;, score=0.819 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2;, score=0.688 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1;, score=0.793 total time=   0.1s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1;, score=0.775 total time=   0.1s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1;, score=0.795 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.847 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.502 total time=   0.1s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2;, score=0.569 total time=   0.3s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2;, score=0.598 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2;, score=0.692 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1;, score=0.779 total time=   0.5s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.843 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.448 total time=   0.2s\n[CV 5/5] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet;, score=0.682 total time=   0.2s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l2;, score=0.567 total time=   0.2s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l2;, score=0.545 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l1;, score=0.780 total time=   0.1s\n[CV 2/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l1;, score=0.780 total time=   0.1s\n[CV 4/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=l1;, score=0.793 total time=   0.2s\n[CV 1/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.855 total time=   0.2s\n[CV 3/5] END alpha=0.01, loss=perceptron, max_iter=30000, penalty=elasticnet;, score=0.861 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2;, score=0.639 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2;, score=0.800 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2;, score=0.596 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1;, score=0.681 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1;, score=0.754 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.752 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.592 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.586 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l2;, score=0.597 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l2;, score=0.818 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l1;, score=0.747 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=l1;, score=0.725 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.619 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.544 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=10000, penalty=elasticnet;, score=0.744 total time=   0.1s\n[CV 1/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l2;, score=0.785 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l2;, score=0.600 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l2;, score=0.474 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l1;, score=0.702 total time=   0.1s\n[CV 3/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l1;, score=0.720 total time=   0.1s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=l1;, score=0.698 total time=   0.4s\n[CV 2/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.651 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=hinge, max_iter=30000, penalty=elasticnet;, score=0.723 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l2;, score=0.530 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l2;, score=0.734 total time=   0.3s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l2;, score=0.498 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l1;, score=0.688 total time=   0.5s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l1;, score=0.711 total time=   0.1s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=l1;, score=0.706 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.762 total time=   0.3s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.773 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l2;, score=0.609 total time=   0.4s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l2;, score=0.474 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l1;, score=0.752 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l1;, score=0.745 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=l1;, score=0.550 total time=   0.4s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.556 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.758 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=10000, penalty=elasticnet;, score=0.470 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l2;, score=0.757 total time=   0.2s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l2;, score=0.814 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l2;, score=0.686 total time=   0.5s\n[CV 3/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=l1;, score=0.731 total time=   0.3s\n[CV 1/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.528 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.695 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=log_loss, max_iter=30000, penalty=elasticnet;, score=0.766 total time=   0.3s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.546 total time=   0.2s\n[CV 4/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l2;, score=0.582 total time=   0.2s\n[CV 1/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.760 total time=   0.3s\n[CV 3/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.761 total time=   0.3s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=l1;, score=0.763 total time=   0.2s\n[CV 2/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.836 total time=   0.2s\n[CV 5/5] END alpha=0.1, loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.782 total time=   0.2s\n"}},"pos":12,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"d3c4e8","input":"lr_clf = LR()","pos":31,"type":"cell"}
{"cell_type":"code","exec_count":23,"id":"8c5832","input":"lr_clf.fit(x_train, y_train)","output":{"0":{"name":"stderr","output_type":"stream","text":"/projects/72aec78b-4035-4aa5-8faa-4d7af1533e7b/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"},"1":{"data":{"text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>","text/plain":"LogisticRegression()"},"exec_count":23,"output_type":"execute_result"}},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"9b68a1","input":"grid_params = {'n_neighbors':[1,2,3], 'weights':[]}\n\ngs = GSearch(KNN(), grid_params)\ngs.fit(x_train, y_train)","output":{"0":{"ename":"ValueError","evalue":"Parameter grid for parameter 'weights' need to be a non-empty sequence, got: []","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m grid_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m      3\u001b[0m gs \u001b[38;5;241m=\u001b[39m GSearch(KNN(), grid_params)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:125\u001b[0m, in \u001b[0;36mParameterGrid.__init__\u001b[0;34m(self, param_grid)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    119\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter grid for parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m needs to be a list or a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m numpy array, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) instead. Single values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to be wrapped in a list with one element.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             )\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter grid for parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m need \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be a non-empty sequence, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m             )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid \u001b[38;5;241m=\u001b[39m param_grid\n","\u001b[0;31mValueError\u001b[0m: Parameter grid for parameter 'weights' need to be a non-empty sequence, got: []"]}},"pos":38,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"fff62e","input":"lr_pred=lr_clf.predict(x_test)","pos":33,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"e9f14e","input":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, lr_pred), annot=True, fmt='g')\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix');\nax.xaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied',]); ax.yaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied'])\n\nrecall = sklearn.metrics.recall_score(y_test, lr_pred)\nprecision = sklearn.metrics.precision_score(y_test, lr_pred)\naccuracy = sklearn.metrics.accuracy_score(y_test, lr_pred)\nf_measure = sklearn.metrics.f1_score(y_test, lr_pred)\nprint(\"R: \", recall)\nprint(\"P: \", precision)\nprint(\"A: \", accuracy)\nprint(\"F: \", f_measure)\n\n# Sebastian ","output":{"0":{"name":"stdout","output_type":"stream","text":"R:  0.7779849090102086\nP:  0.7825\nA:  0.8093675187273148\nF:  0.7802359225461828\n"},"1":{"data":{"image/png":"15d219bc348fda79f1a905150802ffe490edb64e","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":25,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":34,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"547932","input":"airline_df.isnull().sum()","output":{"0":{"data":{"text/plain":"Age                                  0\nFlight Distance                      0\nInflight wifi service                0\nDeparture/Arrival time convenient    0\nEase of Online booking               0\nGate location                        0\nFood and drink                       0\nOnline boarding                      0\nSeat comfort                         0\nInflight entertainment               0\nOn-board service                     0\nLeg room service                     0\nBaggage handling                     0\nCheckin service                      0\nInflight service                     0\nCleanliness                          0\nDeparture Delay in Minutes           0\nArrival Delay in Minutes             0\nsatisfaction_satisfied               0\nGender_Female                        0\nGender_Male                          0\nCustomer Type_Loyal Customer         0\nCustomer Type_disloyal Customer      0\nType of Travel_Business travel       0\nType of Travel_Personal Travel       0\nClass_Business                       0\nClass_Eco                            0\nClass_Eco Plus                       0\ndtype: int64"},"exec_count":3,"output_type":"execute_result"}},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"4861c2","input":"#svc = SVC(probability=False)","pos":40,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"d6da83","input":"#svc.fit(x_train, y_train)\n#svc_pred = svc.pred(x_test, y_test)","pos":41,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"d8c359","input":"#Neural_model = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(20, 20), random_state=1)\n\n#Neural_model.fit(x_train, y_train)\n\n#Neural_hat = Neural_model.predict(x_test)\n\n#precision = sklearn.metrics.precision_score(y_test, Neural_hat)\n#accuracy = sklearn.metrics.accuracy_score(y_test, Neural_hat)\n#print(\"P: \", precision)\n#print(\"A: \", accuracy)\n\n#sns.heatmap(confusion_matrix(y_test, Neural_hat), annot=True, fmt='g')","pos":15,"type":"cell"}
{"cell_type":"code","exec_count":36,"id":"f1b59d","input":"knn_clf = KNN(n_neighbors=3, weights=\"distance\")\nknn_clf.fit(x_train, y_train)\nknn_pred = knn_clf.predict(x_test)","pos":36,"type":"cell"}
{"cell_type":"code","exec_count":37,"id":"776a05","input":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, knn_pred), annot=True, fmt='g')\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix');\nax.xaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied',]); ax.yaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied'])\n\nrecall = sklearn.metrics.recall_score(y_test, knn_pred)\nprecision = sklearn.metrics.precision_score(y_test, knn_pred)\naccuracy = sklearn.metrics.accuracy_score(y_test, knn_pred)\nf_measure = sklearn.metrics.f1_score(y_test, knn_pred)\nprint(\"R: \", recall)\nprint(\"P: \", precision)\nprint(\"A: \", accuracy)\nprint(\"F: \", f_measure)\n\n# Sebastian ","output":{"0":{"name":"stdout","output_type":"stream","text":"R:  0.6293333333333333\nP:  0.6355475763016158\nA:  0.6822393822393822\nF:  0.6324251898168826\n"},"1":{"data":{"image/png":"99f5bcf44d4f1f57655ee4bb1864e453024e7fc4","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":37,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"d8a3c7","input":"airline_df.columns","output":{"0":{"data":{"text/plain":"Index(['Age', 'Flight Distance', 'Inflight wifi service',\n       'Departure/Arrival time convenient', 'Ease of Online booking',\n       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n       'Inflight entertainment', 'On-board service', 'Leg room service',\n       'Baggage handling', 'Checkin service', 'Inflight service',\n       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes',\n       'satisfaction_satisfied', 'Gender_Female', 'Gender_Male',\n       'Customer Type_Loyal Customer', 'Customer Type_disloyal Customer',\n       'Type of Travel_Business travel', 'Type of Travel_Personal Travel',\n       'Class_Business', 'Class_Eco', 'Class_Eco Plus'],\n      dtype='object')"},"exec_count":4,"output_type":"execute_result"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":41,"id":"785a7c","input":"adc_pred = adc_clf.predict(x_test)","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":43,"id":"e54259","input":"tree_clf = DecisionTreeClassifier()\nadc_clf = ADC()","pos":24,"type":"cell"}
{"cell_type":"code","exec_count":44,"id":"eebb18","input":"adc_clf.fit(x_train, y_train)","output":{"0":{"data":{"text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>","text/plain":"AdaBoostClassifier()"},"exec_count":44,"output_type":"execute_result"}},"pos":26,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":45,"id":"e407fd","input":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, adc_pred), annot=True, fmt='g')\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix');\nax.xaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied',]); ax.yaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied'])\n\nprint(\"Accuracy:\", accuracy_score(y_test, adc_pred))\nprint(\"Precision:\", precision_score(y_test, adc_pred))\nprint(\"Recall:\", recall_score(y_test, adc_pred))\nprint(\"F1 Score:\", f1_score(y_test, adc_pred))\n\n# Sebastian ","output":{"0":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.9212355212355212\nPrecision: 0.9078830823737821\nRecall: 0.9111111111111111\nF1 Score: 0.9094942324755989\n"},"1":{"data":{"image/png":"2fb84cabc4efa3f1a8a75bec14614eafba29747b","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":45,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":29,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"a67919","input":"airline_df.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Flight Distance</th>\n      <th>Inflight wifi service</th>\n      <th>Departure/Arrival time convenient</th>\n      <th>Ease of Online booking</th>\n      <th>Gate location</th>\n      <th>Food and drink</th>\n      <th>Online boarding</th>\n      <th>Seat comfort</th>\n      <th>Inflight entertainment</th>\n      <th>...</th>\n      <th>satisfaction_satisfied</th>\n      <th>Gender_Female</th>\n      <th>Gender_Male</th>\n      <th>Customer Type_Loyal Customer</th>\n      <th>Customer Type_disloyal Customer</th>\n      <th>Type of Travel_Business travel</th>\n      <th>Type of Travel_Personal Travel</th>\n      <th>Class_Business</th>\n      <th>Class_Eco</th>\n      <th>Class_Eco Plus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>460</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>235</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26</td>\n      <td>1142</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25</td>\n      <td>562</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>61</td>\n      <td>214</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>","text/plain":"   Age  Flight Distance  Inflight wifi service  \\\n0   13              460                      3   \n1   25              235                      3   \n2   26             1142                      2   \n3   25              562                      2   \n4   61              214                      3   \n\n   Departure/Arrival time convenient  Ease of Online booking  Gate location  \\\n0                                  4                       3              1   \n1                                  2                       3              3   \n2                                  2                       2              2   \n3                                  5                       5              5   \n4                                  3                       3              3   \n\n   Food and drink  Online boarding  Seat comfort  Inflight entertainment  ...  \\\n0               5                3             5                       5  ...   \n1               1                3             1                       1  ...   \n2               5                5             5                       5  ...   \n3               2                2             2                       2  ...   \n4               4                5             5                       3  ...   \n\n   satisfaction_satisfied  Gender_Female  Gender_Male  \\\n0                       0              0            1   \n1                       0              0            1   \n2                       1              1            0   \n3                       0              1            0   \n4                       1              0            1   \n\n   Customer Type_Loyal Customer  Customer Type_disloyal Customer  \\\n0                             1                                0   \n1                             0                                1   \n2                             1                                0   \n3                             1                                0   \n4                             1                                0   \n\n   Type of Travel_Business travel  Type of Travel_Personal Travel  \\\n0                               0                               1   \n1                               1                               0   \n2                               1                               0   \n3                               1                               0   \n4                               1                               0   \n\n   Class_Business  Class_Eco  Class_Eco Plus  \n0               0          0               1  \n1               1          0               0  \n2               1          0               0  \n3               1          0               0  \n4               1          0               0  \n\n[5 rows x 28 columns]"},"exec_count":5,"output_type":"execute_result"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":83,"id":"83d5b1","input":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred_tree), annot=True, fmt='g')\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix');\nax.xaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied',]); ax.yaxis.set_ticklabels(['0: Not Satisfied', '1: Satisfied'])\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\nprint(\"Precision:\", precision_score(y_test, y_pred_tree))\nprint(\"Recall:\", recall_score(y_test, y_pred_tree))\nprint(\"F1 Score:\", f1_score(y_test, y_pred_tree))","output":{"0":{"name":"stdout","output_type":"stream","text":"P:  0.7256364823277068\nA:  0.7518727314850567\n"},"1":{"data":{"image/png":"cc46830565446b994f48c527f4d19f12cc64fb7a","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":83,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"markdown","id":"1ecb36","input":"**Random Forest**\n\nA random forest is a model that makes a given number of randomized decision trees and uses them to make predictions on the data by using averaging functions to combine its results from several decision trees, making a more accurate/realistic prediction. Randomizing decision trees allows the model to individually look for correlations between sections of the dataset, making predictions more intuitive, compared to looking at the entire dataset through one decision tree, where it is harder to find patterns when there are so many variables to consider. It then takes the accuracy of the models it makes and displays them on the heatmap so that we can see how accurate/precise the model is. Through some light hyperparameter tuning, we found that at around 20 decision trees, there was no more improvement in the performance of the model and subsequent additions to the amount of decision trees would just increase the processing time. There were also no differences in accuracy/precision when we tried different criterion such as \"entropy\" and \"log\\_loss\", so we decided that \"gini\", the default criterion, was good enough for the model.\n\n- What are the pros and cons of the random forest\n- [https://towardsdatascience.com/hyperparameter\\-tuning\\-the\\-random\\-forest\\-in\\-python\\-using\\-scikit\\-learn\\-28d2aa77dd74](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)\n\n","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"3b8bf2","input":"**Adaboost**\n\nShort for adaptive boosting, Adaboost takes combines models together to create the best model possible. It takes a bunch of weak learners and combines them into strong learners. It takes a number of desicion trees during the data training period. As the first model is made the incorrect values are the input for the next model to be made.\n","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"821caa","input":"a Decision Tree Classifier makes various questions to help determine what group a variable falls into. it goes from the top, and depending on how a question is answered it goes down a path to a different leaf in the tree. It goes all the way down and at the end it puts that variable into a group\n\n- What is a splitting criteron\n- What are the pros and cons?\n- \n\n","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"a6c6e6","input":"<u>Models to make:</u>\n\n- knn\n- decision tree\n- Random forest\n- SVC \\(DON'T DO THIS ONE YET\\)\n- Logistic regression \n- Adaboost \n- \n\nScoring me\ntrics:\n\n- f1 score\n- Recall\n- Precision \n- Accuracy\n\n","pos":43,"type":"cell"}
{"cell_type":"markdown","id":"c8e63a","input":"**Categorical Naive Bayes**\n\nThe categorical Naive Bayes model works using the Bayes Theorem, which assumes that individual features are independent on each other, which works well with our dataset, as we can see through our correlation matrix that none of our features are very correlated. Applying the Bayes Theorem assigns a probability to each feature in the dataset, then uses those probabilities to predict a whole outcome. The categorical Native Bayes model works best for categorical data, which works well with our dataset, as we have a lot of categorical data in the form of 1\\-5 ratings for the airline's performance.\n\n","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"f9c209","input":"<u>What is a KNN:</u>\n\nA KNN is a classification model and can be used for both supervised and unsupervised machine learning. KNN works by finding the distance between a query and all the examples in the data. K is then used to select the number of examples closest to the query. the KNN then votes for the most frequent label. \n\n- - [https://towardsdatascience.com/machine\\-learning\\-basics\\-with\\-the\\-k\\-nearest\\-neighbors\\-algorithm\\-6a6e71d01761](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)\n- What does the K mean?\n  - [https://towardsdatascience.com/a\\-simple\\-introduction\\-to\\-k\\-nearest\\-neighbors\\-algorithm\\-b3519ed98e](https://towardsdatascience.com/a-simple-introduction-to-k-nearest-neighbors-algorithm-b3519ed98e)\n  - K means a parameter that shows the number of nearest neighbors. This is necessary for the voting process.\n\nGrid search:\n\n[https://scikit\\-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n\n[https://medium.com/@erikgreenj/k\\-neighbors\\-classifier\\-with\\-gridsearchcv\\-basics\\-3c445ddeb657](https://medium.com/@erikgreenj/k-neighbors-classifier-with-gridsearchcv-basics-3c445ddeb657)\n\n","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"fc63a1","input":"**Decision Tree:**\n\nA decision tree is a graph that classifies items and whether it is true or false to the question in the box. In this example, we use satisfied for true and false for dissatisfied.\n\n","pos":21,"type":"cell"}
{"id":0,"time":1657819571842,"type":"user"}
{"last_load":1657810014319,"type":"file"}